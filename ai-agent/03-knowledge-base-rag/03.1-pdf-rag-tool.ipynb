{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6be72246-a1e8-4cca-afa9-34dde8f0ee94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Building a knowledge base from PDF documentation using Databricks Vector search (RAG)\n",
    "\n",
    "As we saw before, our agent isn't working well when it comes to answer specific, technical questions such as WIFI router error code.\n",
    "\n",
    "That's because it doesn't have any knowledge about our internal systems and product. \n",
    "\n",
    "Thanksfully, all this information is available to us as PDF. These pdf are stored in our volume. \n",
    "\n",
    "We'll parse them and save them in our Vector Search, and then add a retriever to our agent to improve its capabilities!\n",
    "\n",
    "\n",
    "<div style=\"background-color: #d4e7ff; padding: 10px; border-radius: 15px;\">\n",
    "<strong>Note:</strong> Coming soon, we'll show how to add a Knowledge base in a few clicks leveraging Databricks Agents!\n",
    "</div>\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection or disable tracker during installation. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=data-science&org_id=2839100535698919&notebook=%2F03-knowledge-base-rag%2F03.1-pdf-rag-tool&demo_name=ai-agent&event=VIEW&path=%2F_dbdemos%2Fdata-science%2Fai-agent%2F03-knowledge-base-rag%2F03.1-pdf-rag-tool&version=1\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d23de85d-841c-4cb0-93dd-2f51632c8c06",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Library Installs"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq mlflow>=3.1.4 langchain==0.3.27 langgraph==0.6.11 databricks-langchain pydantic databricks-agents unitycatalog-langchain[databricks] databricks-feature-engineering==0.12.1 protobuf<5  cryptography<43 databricks-mcp\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95aa9fb4-1d17-4af6-a5ff-4d9b6c50f56e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ../_resources/01-setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f48edc4-0dc2-467b-b543-fa0ad1a53959",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## 1. Extracting the PDF information\n",
    "Databricks provides a builtin `ai_parse_document` function, leveraging AI to analyze and extract PDF information as text. This makes it super easy to ingest unstructured information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfaa4708-f531-4c7b-953f-17de209241c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT path FROM READ_FILES('/Volumes/main/dbdemos_ai_agent/raw_data/pdf_documentation/', format => 'binaryFile') limit 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cee86a6c-d5d0-479a-b08d-64707e9191d3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "let's try our ai_parse_document function"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- ai_parse_document is available in DBR 17.1 or serverless runtime\n",
    "SELECT ai_parse_document(content) AS parsed_document\n",
    "  FROM READ_FILES('/Volumes/main/dbdemos_ai_agent/raw_data/pdf_documentation/', format => 'binaryFile') limit 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40dea83e-6dd9-422d-a22b-b82ce80a424f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1.1/ Create our knowledge base table\n",
    "\n",
    "Let's first create our table. We'll enable Change Data Feed so that we can create our vector search on top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c63aa57b-7258-4c87-a54c-00ce8c14929a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS knowledge_base (\n",
    "  id BIGINT GENERATED ALWAYS AS IDENTITY,\n",
    "  product_name STRING,\n",
    "  title STRING,\n",
    "  content STRING,\n",
    "  doc_uri STRING)\n",
    "  TBLPROPERTIES (delta.enableChangeDataFeed = true);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dec95ffd-3fd8-4fed-921e-833b53bcf367",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## 1.2/ PDF to text with ai_parse_document\n",
    "\n",
    "Let's now use Databricks built in `ai_parse_document` function to automatically parse the PDF document for us, making it super easy to extract the information!\n",
    "\n",
    "*Note: in this case, we have relatively small pdf documents, so we'll merge all the pages of the document in one single text field for our RAG system to work properly. Bigger docs might need some pre-processing steps to potentially reduce context size and be able to search/retreive more documents, adding potential pre-processing steps, for example ensuring the WIFI Router model is present in all the chunk to keep the vector search more relevant.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "236443f4-f3a6-4abb-903c-1ddc802efa90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "INSERT OVERWRITE TABLE knowledge_base (product_name, title, content, doc_uri)\n",
    "SELECT ai_extract.product_name, ai_extract.title, content, doc_uri\n",
    "FROM (\n",
    "  SELECT\n",
    "    ai_extract(content, array('product_name', 'title')) AS ai_extract,\n",
    "    content,\n",
    "    doc_uri\n",
    "  FROM (\n",
    "    SELECT array_join(\n",
    "            transform(parsed_document:document.elements::ARRAY<STRUCT<content:STRING>>, x -> x.content), '\\n') AS content,\n",
    "           path as doc_uri\n",
    "    FROM (\n",
    "      SELECT ai_parse_document(content) AS parsed_document, path\n",
    "      FROM READ_FILES('/Volumes/main/dbdemos_ai_agent/raw_data/pdf_documentation/', format => 'binaryFile') \n",
    "      LIMIT 5 -- ADDED FIX LIMIT FOR DEMO COST - DROP IT IN REAL WORKLOAD\n",
    "    )\n",
    "  )\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a20c9c7-d733-4010-88d0-8356a6f54bc2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Check results"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM knowledge_base;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "9248ea1e-ef25-4a3d-9844-96fc41bb1e3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## 2/ Create our vector search table\n",
    "\n",
    "### 2.1/ Vector search Endpoints\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/rag-basic-prep-2.png?raw=true\" style=\"float: right; margin-left: 10px\" width=\"400px\">\n",
    "\n",
    "Vector search endpoints are entities where your indexes will live. Think about them as entry point to handle your search request. \n",
    "\n",
    "Let's start by creating our first Vector Search endpoint. Once created, you can view it in the [Vector Search Endpoints UI](#/setting/clusters/vector-search). Click on the endpoint name to see all indexes that are served by the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "829fba9b-ebbd-4d88-8844-19df22cafbeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.vector_search.client import VectorSearchClient\n",
    "vsc = VectorSearchClient(disable_notice=True)\n",
    "\n",
    "if not endpoint_exists(vsc, VECTOR_SEARCH_ENDPOINT_NAME):\n",
    "    vsc.create_endpoint(name=VECTOR_SEARCH_ENDPOINT_NAME, endpoint_type=\"STANDARD\")\n",
    "\n",
    "wait_for_vs_endpoint_to_be_ready(vsc, VECTOR_SEARCH_ENDPOINT_NAME)\n",
    "print(f\"Endpoint named {VECTOR_SEARCH_ENDPOINT_NAME} is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "9f4f5969-f9bf-4ead-84f5-60780f801808",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/chatbot-rag/rag-basic-prep-3.png?raw=true\" style=\"float: right; margin-left: 10px\" width=\"400px\">\n",
    "\n",
    "\n",
    "### 2.2/ Creating the Vector Search Index\n",
    "\n",
    "Once the endpoint is created, all we now have to do is to as Databricks to create the index on top of the existing table. \n",
    "\n",
    "You just need to specify the text column and our embedding foundation model (`GTE`).  Databricks will build and synchronize the index automatically for us.\n",
    "\n",
    "Note that Databricks provides 3 type of vector search:\n",
    "\n",
    "* **Managed embeddings**: Databricks creates the embeddings for you from a text field and Databricks synchronize the Delta table to your index (what we'll use)\n",
    "* **Self managed embeddings**: You compute the embeddings yourself and save them to your Delta table  and Databricks synchronize the Delta table to your index\n",
    "* **Direct access**: you manage the VS indexation yourself (no Delta table)\n",
    "\n",
    "This can be done using the API, or in a few clicks within the Unity Catalog Explorer menu:\n",
    "\n",
    "<img src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/index_creation.gif?raw=true\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "29037afe-e216-4719-b70e-48628fca2015",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get the Latest Return in the Processing Queue"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "\n",
    "#The table we'd like to index\n",
    "source_table_fullname = f\"{catalog}.{dbName}.knowledge_base\"\n",
    "# Where we want to store our index\n",
    "vs_index_fullname = f\"{catalog}.{dbName}.knowledge_base_vs_index\"\n",
    "\n",
    "if not index_exists(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname):\n",
    "  print(f\"Creating index {vs_index_fullname} on endpoint {VECTOR_SEARCH_ENDPOINT_NAME}...\")\n",
    "  vsc.create_delta_sync_index(\n",
    "    endpoint_name=VECTOR_SEARCH_ENDPOINT_NAME,\n",
    "    index_name=vs_index_fullname,\n",
    "    source_table_name=source_table_fullname,\n",
    "    pipeline_type=\"TRIGGERED\",\n",
    "    primary_key=\"id\",\n",
    "    embedding_source_column='content', #The column containing our text\n",
    "    embedding_model_endpoint_name='databricks-gte-large-en' #The embedding endpoint used to create the embeddings\n",
    "  )\n",
    "  #Let's wait for the index to be ready and all our embeddings to be created and indexed\n",
    "  wait_for_index_to_be_ready(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname)\n",
    "else:\n",
    "  #Trigger a sync to update our vs content with the new data saved in the table\n",
    "  wait_for_index_to_be_ready(vsc, VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname)\n",
    "  vsc.get_index(VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname).sync()\n",
    "\n",
    "print(f\"index {vs_index_fullname} on table {source_table_fullname} is ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53fa0449-477d-425c-9854-8941eabae75e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 2.3/ Try our VS index: searching for relevant content\n",
    "\n",
    "That's all we have to do. Databricks will automatically capture and synchronize new entries in your table with the index.\n",
    "\n",
    "Note that depending on your dataset size and model size, index creation can take a few seconds to start and index your embeddings.\n",
    "\n",
    "Let's give it a try and search for similar content.\n",
    "\n",
    "*Note: `similarity_search` also support a filters parameter. This is useful to add a security layer to your RAG system: you can filter out some sensitive content based on who is doing the call (for example filter on a specific department based on the user preference).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "70682aba-5dd1-480c-9c01-205ad92aec73",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create a function registered to Unity Catalog"
    }
   },
   "outputs": [],
   "source": [
    "question = \"My wifi router gives me error 01, what should I do?\"\n",
    "\n",
    "results = vsc.get_index(VECTOR_SEARCH_ENDPOINT_NAME, vs_index_fullname).similarity_search(\n",
    "  query_text=question,\n",
    "  columns=[\"id\", \"content\"],\n",
    "  num_results=1)\n",
    "docs = results.get('result', {}).get('data_array', [])\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11c5cbad-6869-4322-8bc6-89f4622babce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 3/ Update our existing Agent to add the retriever as new tool\n",
    "\n",
    "Now that our index is ready, all we have to do is to add it as retriever to our existing agent!\n",
    "\n",
    "We'll reuse the `agent.py` and `agent_config.yaml` file: simply add the retriever configuration and our agent will add it as one of the tools available!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d7abb98-5453-4fde-bdd5-431c9828b9e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import yaml, sys, os\n",
    "import mlflow.models\n",
    "# Add the ../agent_eval path relative to current working directory\n",
    "agent_eval_path = os.path.abspath(os.path.join(os.getcwd(), \"../02-agent-eval\"))\n",
    "sys.path.append(agent_eval_path)\n",
    "# Let's also use the same experiment as in our previous notebook to keep all the trace in a single place\n",
    "mlflow.set_experiment(agent_eval_path+\"/02.1_agent_evaluation\")\n",
    "conf_path = os.path.join(agent_eval_path, 'agent_config.yaml')\n",
    "\n",
    "try:\n",
    "    config = yaml.safe_load(open(conf_path))\n",
    "    config[\"config_version_name\"] = \"model_with_retriever\"\n",
    "    config[\"retriever_config\"] =  {\n",
    "        \"index_name\": vs_index_fullname,\n",
    "        \"tool_name\": \"product_technical_docs_retriever\",\n",
    "        \"num_results\": 1,\n",
    "        \"description\": \"Retrieves internal documentation about our products, infrastructure, router and other, including features, usage, and troubleshooting. Use this tool for any questions about product documentation or product issues.\"\n",
    "    }\n",
    "    yaml.dump(config, open(conf_path, \"w\"))\n",
    "except Exception as e:\n",
    "    print(f\"Skipped update - ignore for job run - {e}\")\n",
    "\n",
    "model_config = mlflow.models.ModelConfig(development_config=conf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8babfdde-091d-4d39-ba8e-407d28f5f394",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-mcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "518276be-d79f-45c7-8681-1e3daf750610",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agent import AGENT \n",
    "\n",
    "#Let's try our retriever to make sure we know have access to the wifi router pdf guide\n",
    "request_example = \"How do I restart my WIFI router ADSL-R500?\"\n",
    "answer = AGENT.predict({\"input\":[{\"role\": \"user\", \"content\": request_example}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d62f5127-82c1-44a2-8d5f-5fb8a0336c15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now log the new agent in the MLflow model registry using `mlflow.pyfunc.log_model()` as in the notebook `02.1_agent evaluation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63b9eba8-9793-43b0-918f-efcccdd9e13f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Agent captures required resources for agent execution, note that it now has the VS index referenced\n",
    "for r in AGENT.get_resources():\n",
    "  print(f\"Resource: {type(r).__name__}:{r.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "495773dd-66e5-4a8f-a36f-624f534e53dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=model_config.get('config_version_name')):\n",
    "  logged_agent_info = mlflow.pyfunc.log_model(\n",
    "    name=\"agent\",\n",
    "    python_model=agent_eval_path+\"/agent.py\",\n",
    "    model_config=conf_path,\n",
    "    input_example={\"input\": [{\"role\": \"user\", \"content\": request_example}]},\n",
    "     # Determine resources (endpoints, fonctions, vs...) to specify for automatic auth passthrough for deployment\n",
    "    resources=AGENT.get_resources(),\n",
    "    extra_pip_requirements=[\"databricks-connect\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80edcc55-1965-4023-b47b-e9c2b461dac7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 4/ Evaluate our agent against our documents base\n",
    "\n",
    "Our new model is available! As usual, the next step is to evaluate our dataset to make sure we're improving our answers.\n",
    "\n",
    "\n",
    "### 4.1/ Generate synthetic eval data\n",
    "\n",
    "Note that our eval dataset doesn't have any entry on our PDF.\n",
    "\n",
    "Using Databricks, it's easy to bootstrap our evaluation dataset with synthetic eval data, and then improve this dataset over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89aefda5-1393-4c7b-aa87-b3b05ff9dd1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.agents.evals import generate_evals_df\n",
    "\n",
    "docs = spark.table('knowledge_base')\n",
    "# Describe what our agent is doing\n",
    "agent_description = \"\"\"\n",
    "The Agent is a RAG chatbot that answers technical questions about products such as wifi router, Fiber Installation, network information, but also customer retention strategies or guidelines on social media. The Agent has access to a corpus of Documents, and its task is to answer the user's questions by retrieving the relevant docs from the corpus and synthesizing a helpful, accurate response.\n",
    "\"\"\"\n",
    "\n",
    "question_guidelines = \"\"\"\n",
    "# User personas\n",
    "- A customer asking question on how to troubleshoot the system, step by step\n",
    "- An internal agent asking question on internal policies\n",
    "\n",
    "# Example questions\n",
    "- How do I troubleshoot Error Code 1001: Invalid Return Authorization when a customer can't submit their return request?\n",
    "- I'm getting Error Code 1001 when trying to deploy a survey. What could be causing this and how do I fix it?\n",
    "\n",
    "# Additional Guidelines\n",
    "- Questions should be succinct, and human-like\n",
    "\"\"\"\n",
    "\n",
    "# Generate synthetic eval dataset\n",
    "evals = generate_evals_df(\n",
    "    docs,\n",
    "    # The total number of evals to generate. The method attempts to generate evals that have full coverage over the documents\n",
    "    # provided. If this number is less than the number of documents,\n",
    "    # some documents will not have any evaluations generated. See \"How num_evals is used\" below for more details.\n",
    "    num_evals=10\n",
    "    ,\n",
    "    # A set of guidelines that help guide the synthetic generation. These are free-form strings that will be used to prompt the generation.\n",
    "    agent_description=agent_description,\n",
    "    question_guidelines=question_guidelines\n",
    ")\n",
    "evals[\"inputs\"] = evals[\"inputs\"].apply(lambda x: {\"question\": x[\"messages\"][0][\"content\"]})\n",
    "display(evals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ed8ff299-4461-453a-9e5f-a5abdf8bb4da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add our synthetic dataset to our MLFLow evaluation dataset\n",
    "eval_dataset_table_name = f\"{catalog}.{dbName}.ai_agent_mlflow_eval\"\n",
    "\n",
    "eval_dataset = mlflow.genai.datasets.get_dataset(eval_dataset_table_name)\n",
    "eval_dataset.merge_records(evals)\n",
    "print(\"Added records to the evaluation dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "adc73d04-4325-4765-9eef-cef443bc8e7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.2/ Running our evaluation\n",
    "As previously, let's run our evaluations using the MLFlow dataset. We'll make sure our model still behave properly on the customer-related question, and now perform well on our knowledge-base questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "143eab05-7755-456c-b0b6-c9845161b91b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.genai.scorers import RetrievalGroundedness, RelevanceToQuery, Safety, Guidelines\n",
    "import pandas as pd\n",
    "\n",
    "eval_dataset = mlflow.genai.datasets.get_dataset(f\"{catalog}.{dbName}.ai_agent_mlflow_eval\")\n",
    "\n",
    "#Get the same scorers as previously (function is defined in _resources/01-setup, similar to the previous step)\n",
    "scorers = get_scorers()\n",
    "\n",
    "# Load the model and create a prediction function\n",
    "loaded_model = mlflow.pyfunc.load_model(f\"runs:/{logged_agent_info.run_id}/agent\")\n",
    "def predict_wrapper(question):\n",
    "    # Format for chat-style models\n",
    "    model_input = pd.DataFrame({\n",
    "        \"input\": [[{\"role\": \"user\", \"content\": question}]]\n",
    "    })\n",
    "    response = loaded_model.predict(model_input)\n",
    "    return response['output'][-1]['content'][-1]['text']\n",
    "    \n",
    "print(\"Running evaluation...\")\n",
    "with mlflow.start_run(run_name='eval_with_retriever'):\n",
    "    results = mlflow.genai.evaluate(data=eval_dataset, predict_fn=predict_wrapper, scorers=scorers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "164c6c3d-da49-40cb-b8ca-7e079f7b1e19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.3/ Deploy the final model! \n",
    "\n",
    "We're good to go. Let's deploy our model to UC and update our endpoint with the latest version!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58cd0951-621a-4e7a-9493-22395f573fbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "MODEL_NAME = \"dbdemos_ai_agent_demo\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{dbName}.{MODEL_NAME}\"\n",
    "\n",
    "# register the model to UC\n",
    "client = MlflowClient()\n",
    "uc_registered_model_info = mlflow.register_model(model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME, tags={\"model\": \"customer_support_agent\", \"model_version\": \"with_retriever\"})\n",
    "\n",
    "client.set_registered_model_alias(name=UC_MODEL_NAME, alias=\"model-to-deploy\", version=uc_registered_model_info.version)\n",
    "displayHTML(f'<a href=\"/explore/data/models/{catalog}/{dbName}/{MODEL_NAME}\" target=\"_blank\">Open Unity Catalog to see Registered Agent</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4883a64-f94e-43b3-b9e5-f1160c23cc7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import agents\n",
    "# Deploy the model to the review app and a model serving endpoint\n",
    "endpoint_name = f'{MODEL_NAME}_{catalog}_{db}'[:60]\n",
    "\n",
    "if len(agents.get_deployments(model_name=UC_MODEL_NAME, model_version=uc_registered_model_info.version)) == 0:\n",
    "  agents.deploy(UC_MODEL_NAME, uc_registered_model_info.version, endpoint_name=endpoint_name, tags = {\"project\": \"dbdemos\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9c4f7b6-4e4e-4466-8d57-72eea17d5873",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Next: deploy our chatbout within a Databricks Application\n",
    "\n",
    "Now that our agent is ready, let's deploy a GradIO application to serve its content to our end users. \n",
    "\n",
    "Open [04-deploy-app/04-Deploy-Frontend-Lakehouse-App]($../04-deploy-app/04-Deploy-Frontend-Lakehouse-App) !"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "03.1-pdf-rag-tool",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
